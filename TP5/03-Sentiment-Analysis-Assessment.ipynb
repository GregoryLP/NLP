{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation de l'analyse des sentiments - Solution\n",
    "\n",
    "## Tâche #1 : Effectuer une arithmétique vectorielle sur vos propres mots\n",
    "Écrivez un code qui évalue l'arithmétique vectorielle sur votre propre ensemble de mots apparentés. L'objectif est de se rapprocher le plus possible d'un mot attendu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library. Remember to use a larger model!\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.8360e+00, -2.1528e+00,  1.1007e+00,  4.9574e-01,  3.8800e-01,\n",
       "       -1.6602e+00,  2.2764e+00,  4.4135e-01,  2.5298e-01,  1.2453e-01,\n",
       "        8.5768e-01,  6.2674e-01, -5.5388e-03, -2.9430e+00, -8.9161e-01,\n",
       "       -1.9106e-01, -5.7977e-01,  3.2566e+00, -4.2386e-01,  9.9431e-01,\n",
       "       -3.7463e-01,  8.6264e-01,  2.2904e+00,  1.5030e+00,  1.3459e+00,\n",
       "        3.0054e-01,  4.2644e-01,  1.2759e+00,  1.9138e+00, -1.3465e+00,\n",
       "       -2.1362e+00,  1.1462e+00,  2.5568e+00,  1.2329e+00, -4.4610e+00,\n",
       "       -2.8898e+00,  1.6285e-01, -2.0797e+00, -1.0619e+00, -1.2581e+00,\n",
       "        1.0161e+00, -1.2740e+00, -1.4286e+00,  3.7070e+00,  1.4562e+00,\n",
       "       -2.4048e+00,  1.5115e+00,  2.0395e+00,  5.4555e-01,  9.7015e-01,\n",
       "       -1.2786e+00, -5.1217e-01, -1.2907e+00,  3.4015e+00,  2.2860e+00,\n",
       "       -1.6315e+00,  1.2485e+00, -7.4508e-01, -1.4559e+00, -3.1660e+00,\n",
       "       -1.3820e+00,  3.4164e-01, -2.0005e+00,  9.8657e-01,  4.2713e+00,\n",
       "        1.1252e+00, -1.5206e+00, -6.9367e-01,  2.0303e+00, -1.0241e+00,\n",
       "        1.3664e+00, -1.6321e+00,  1.2141e+00, -1.0995e+00, -1.0974e+00,\n",
       "        3.2818e+00, -1.4016e+00,  1.8606e+00, -1.0616e+00,  1.6575e+00,\n",
       "        2.3847e+00, -1.7717e+00, -2.2663e+00,  2.9214e+00,  7.5499e-01,\n",
       "        1.5514e+00, -1.5086e+00,  4.6678e-01, -2.0139e+00, -1.5683e+00,\n",
       "       -2.3814e+00, -1.9035e+00,  1.1170e+00,  8.9194e-01, -8.8395e-01,\n",
       "       -5.3855e+00, -2.9981e+00,  9.9391e-01, -2.2953e-01,  2.3684e+00,\n",
       "       -1.5914e-01,  1.9443e+00, -1.9311e+00,  7.1398e-01,  1.9118e+00,\n",
       "       -1.8877e-01,  1.6930e+00, -1.9694e+00,  3.0997e+00, -1.9323e+00,\n",
       "       -1.1686e+00,  3.0416e-02,  7.6595e-01,  1.0726e+00,  2.1460e+00,\n",
       "       -4.3406e+00,  2.8742e+00,  1.9343e+00, -3.3862e+00,  1.6787e+00,\n",
       "       -2.0292e+00, -1.6343e-01,  2.7357e+00, -1.5124e-01, -1.2849e+00,\n",
       "        1.3524e+00,  1.2789e+00, -9.0442e-01,  1.0288e+00, -1.8225e+00,\n",
       "       -3.0547e+00,  7.9252e-01,  8.3732e-02, -3.5359e+00,  3.6104e-01,\n",
       "       -6.2318e-01,  3.2078e+00,  3.9128e-01,  1.7861e+00,  1.8939e+00,\n",
       "       -1.4875e+00, -1.4379e-01,  8.1126e-01,  1.1010e-01,  2.6781e+00,\n",
       "        2.6327e+00, -2.0153e+00,  1.5973e+00, -2.8714e+00, -1.6206e+00,\n",
       "        3.7826e+00,  1.5348e+00, -4.7826e-01,  1.2316e+00, -9.1216e-01,\n",
       "       -6.4336e-01, -2.1554e+00, -5.1133e-01, -2.7723e-02,  9.0708e-02,\n",
       "        1.5390e+00, -4.4743e+00,  3.1356e+00,  5.3679e-01, -1.9364e+00,\n",
       "        1.3121e+00, -4.7258e-01, -2.5106e-01, -2.2737e+00, -8.4649e-01,\n",
       "        1.1795e+00, -2.1558e+00, -2.0114e+00, -2.0281e+00,  2.5762e+00,\n",
       "       -2.8033e-01, -5.0910e-01,  2.6292e-01, -1.7937e+00, -1.8377e+00,\n",
       "       -1.9929e-01, -7.3095e-01, -1.6465e+00,  1.5916e+00,  4.3540e+00,\n",
       "        2.1857e-01,  3.4954e+00, -2.4477e+00,  5.5004e-01,  3.3028e+00,\n",
       "        9.8911e-01, -2.3470e+00,  2.4278e+00,  1.7568e+00,  1.7287e+00,\n",
       "        1.2825e-01,  1.9032e+00, -1.9761e+00,  1.5410e+00,  2.5078e+00,\n",
       "        2.3372e+00, -4.0458e-01, -6.7244e-01,  3.1502e-01,  6.2385e-02,\n",
       "       -1.4715e-01, -3.7906e-01,  5.6552e-01,  1.0900e-01,  1.0494e+00,\n",
       "       -2.8337e+00, -2.5386e+00,  2.5670e+00,  1.3194e+00, -9.5822e-01,\n",
       "       -4.0058e-01, -3.3900e+00,  2.5012e+00,  2.0750e+00, -2.5346e+00,\n",
       "        5.7663e-01, -1.0661e+00, -2.4973e-01,  1.3727e+00, -4.4097e-01,\n",
       "        2.4501e+00,  4.4345e-01,  1.8468e+00, -1.8320e+00, -1.6387e-03,\n",
       "        1.5854e+00,  3.0873e+00, -4.5628e-01, -6.4809e-01,  1.6148e+00,\n",
       "       -5.6181e-01, -1.6349e+00,  1.2186e+00, -2.4541e+00, -1.7463e+00,\n",
       "        3.1691e-01, -5.8989e-01,  9.2000e-01, -6.8354e-01,  2.1984e+00,\n",
       "        3.5852e-01,  1.4871e+00, -1.4612e+00,  3.9356e-01, -1.3749e+00,\n",
       "       -9.4633e-01, -1.4824e+00, -4.5774e-01,  1.5803e+00, -8.0425e-02,\n",
       "        1.6557e+00,  3.6886e-01, -2.1754e+00,  1.1686e+00, -7.0782e-01,\n",
       "       -1.4068e+00, -2.2901e+00,  1.3902e+00, -4.9078e-01, -7.7099e-01,\n",
       "       -1.4672e+00, -6.8098e-01,  1.3106e+00, -3.3063e-01,  1.9810e-01,\n",
       "        9.3151e-01,  3.5435e-01, -3.2586e+00,  3.0762e+00,  1.7336e+00,\n",
       "       -2.1455e-01, -1.2956e+00,  3.8260e-01, -2.1311e-01,  1.7019e+00,\n",
       "       -9.0053e-01, -1.3764e+00,  2.3781e+00, -1.5214e+00,  1.7217e+00,\n",
       "       -3.2308e-01,  1.4768e+00,  1.7059e+00, -1.7561e+00, -1.2040e+00,\n",
       "        1.2098e+00, -1.1872e+00, -1.7058e+00,  1.6532e-01, -3.6248e+00,\n",
       "       -9.4482e-01,  1.6034e+00, -8.4996e-02,  1.1759e-01,  8.1543e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the words you wish to compare, and obtain their vectors\n",
    "nlp(u'Gregory').vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spatial and define a cosine_similarity function\n",
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toto', 'tata', 'o', 'u', 'j', 'ü', 'r', 'f', 'em', 'w']\n"
     ]
    }
   ],
   "source": [
    "# Write an expression for vector arithmetic\n",
    "# For example: new_vector = word1 - word2 + word3\n",
    "\n",
    "toto = nlp.vocab['toto'].vector\n",
    "titi = nlp.vocab['titi'].vector\n",
    "tata = nlp.vocab['tata'].vector\n",
    "\n",
    "new_vector = toto - titi + tata\n",
    "computed_similarities = []\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(new_vector, word.vector)\n",
    "                computed_similarities.append((word, similarity))\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "print([w[0].text for w in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the top ten closest vectors in the vocabulary to the result of the expression above\n",
    "# voir ci dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DÉFI : Écrire une fonction qui prend 3 chaînes de caractères, effectue l'arithmétique a-b+c et renvoie un résultat de dix premiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_math(a,b,c):\n",
    "    a = nlp.vocab[a].vector\n",
    "    b = nlp.vocab[b].vector\n",
    "    c = nlp.vocab[c].vector\n",
    "    new_vector = a - b + c\n",
    "    computed_similarities = []\n",
    "    for word in nlp.vocab:\n",
    "        if word.has_vector:\n",
    "            if word.is_lower:\n",
    "                if word.is_alpha:\n",
    "                    similarity = cosine_similarity(new_vector, word.vector)\n",
    "                    computed_similarities.append((word, similarity))\n",
    "    computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "    return [w[0].text for w in computed_similarities[:10]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['king',\n",
       " 'and',\n",
       " 'that',\n",
       " 'havin',\n",
       " 'where',\n",
       " 'she',\n",
       " 'they',\n",
       " 'woman',\n",
       " 'somethin',\n",
       " 'there']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function on known words:\n",
    "vector_math('king','man','woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tâche #2 : Effectuer une analyse de sentiment VADER sur votre propre commentaire\n",
    "Écrivez un code qui renvoie un ensemble de scores de polarité SentimentIntensityAnalyzer sur la base de votre propre critique écrite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\grego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a review as one continuous string (multiple sentences are ok)\n",
    "review = 'This was a good film and series.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.633, 'pos': 0.367, 'compound': 0.4404}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the sid scores for your review\n",
    "sid.polarity_scores(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DÉFI : Écrire une fonction qui prend en compte un avis et renvoie une note \"positive\", \"négative\" ou \"neutre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_rating(string):\n",
    "    scores = sid.polarity_scores(string)\n",
    "    if scores['compound'] == 0:\n",
    "        return 'Neutral'\n",
    "    elif scores['compound'] > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function on your review above:\n",
    "review_rating(review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
